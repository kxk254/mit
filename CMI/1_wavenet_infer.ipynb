{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5141458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly\n",
    "# !pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa704ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "�T�u�f�B���N�g���܂��̓t�@�C�� output �͊��ɑ��݂��܂��B\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "# import kaggle_evaluation.cmi_inference_server\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "!mkdir output\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14305562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    BATCH_SIZE_TEST = 1\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "\n",
    "class paths:\n",
    "    OUTPUT_DIR = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\output\"\n",
    "    TEST_CSV = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\test.csv\"\n",
    "    TEST_DEMOGRAPHICS = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\test_demographics.csv\"\n",
    "    TRAIN_CSV = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS = \"C:\\\\Users\\\\konno\\\\SynologyDrive\\\\datasciense\\\\projects_foler\\\\1_kaggle\\\\CMI\\\\cmi-detect-behavior-with-sensor-data\\\\train_demographics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f34a4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_scoring(df_preds: pd.DataFrame) ->tuple[pd.DataFrame, pd.DataFrame]: \n",
    "    solution = df_preds[[\"sequence_id\", \"y_true\"]].copy()\n",
    "    solution.columns = [\"id\", \"gesture\"]\n",
    "    solution[\"gesture\"] = solution[\"gesture\"].map(num_to_label)\n",
    "\n",
    "    submission = df_preds[[\"sequence_id\", \"y_pred\"]].copy()\n",
    "    submission.columns = [\"id\", \"gesture\"]\n",
    "    submission[\"gesture\"] = submission[\"gesture\"].map(num_to_label)\n",
    "    \n",
    "    return solution, submission\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "    \n",
    "\n",
    "def sep():\n",
    "    print(\"—\"*100)\n",
    "\n",
    "\n",
    "label_to_num = {\n",
    "    'Above ear - pull hair': 0,  # < ------- TARGETS START\n",
    "    'Cheek - pinch skin': 1,\n",
    "    'Eyebrow - pull hair': 2,\n",
    "    'Eyelash - pull hair': 3,\n",
    "    'Forehead - pull hairline': 4,\n",
    "    'Forehead - scratch': 5,\n",
    "    'Neck - pinch skin': 6,\n",
    "    'Neck - scratch': 7,  # < ------- TARGETS END\n",
    "    'Drink from bottle/cup': 8,  # < ------- NON-TARGETS START\n",
    "    'Feel around in tray and pull out an object': 8,\n",
    "    'Glasses on/off': 8,\n",
    "    'Pinch knee/leg skin': 8,\n",
    "    'Pull air toward your face': 8,\n",
    "    'Scratch knee/leg skin': 8,\n",
    "    'Text on phone': 8,\n",
    "    'Wave hello': 8,\n",
    "    'Write name in air': 8,\n",
    "    'Write name on leg': 8  # < ------- NON-TARGETS END\n",
    "}\n",
    "type_to_num = {\"Target\": 1, \"Non-Target\":0}\n",
    "num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "num_to_type = {v: k for k, v in type_to_num.items()}\n",
    "seed_everything(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0997e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe shape: (107, 336)\n",
      "————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Test demographics dataframe shape: (2, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>...</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001_000000</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.039062</td>\n",
       "      <td>5.261719</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.367188</td>\n",
       "      <td>-0.397400</td>\n",
       "      <td>-0.629028</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000001_000001</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.421875</td>\n",
       "      <td>3.460938</td>\n",
       "      <td>-1.113281</td>\n",
       "      <td>0.353882</td>\n",
       "      <td>-0.507141</td>\n",
       "      <td>-0.652710</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000001_000002</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>10.160156</td>\n",
       "      <td>2.082031</td>\n",
       "      <td>-3.871094</td>\n",
       "      <td>0.384094</td>\n",
       "      <td>-0.532104</td>\n",
       "      <td>-0.639648</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000001_000003</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.773438</td>\n",
       "      <td>1.355469</td>\n",
       "      <td>-4.371094</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>-0.531982</td>\n",
       "      <td>-0.634033</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000001_000004</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.195312</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>-3.222656</td>\n",
       "      <td>0.382751</td>\n",
       "      <td>-0.534180</td>\n",
       "      <td>-0.638367</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              row_id sequence_id  sequence_counter      subject      acc_x  \\\n",
       "0  SEQ_000001_000000  SEQ_000001                 0  SUBJ_055840   9.039062   \n",
       "1  SEQ_000001_000001  SEQ_000001                 1  SUBJ_055840   9.421875   \n",
       "2  SEQ_000001_000002  SEQ_000001                 2  SUBJ_055840  10.160156   \n",
       "3  SEQ_000001_000003  SEQ_000001                 3  SUBJ_055840   9.773438   \n",
       "4  SEQ_000001_000004  SEQ_000001                 4  SUBJ_055840   9.195312   \n",
       "\n",
       "      acc_y     acc_z     rot_w     rot_x     rot_y  ...  tof_5_v54  \\\n",
       "0  5.261719  0.800781  0.367188 -0.397400 -0.629028  ...       97.0   \n",
       "1  3.460938 -1.113281  0.353882 -0.507141 -0.652710  ...      175.0   \n",
       "2  2.082031 -3.871094  0.384094 -0.532104 -0.639648  ...       -1.0   \n",
       "3  1.355469 -4.371094  0.387756 -0.531982 -0.634033  ...       -1.0   \n",
       "4  1.011719 -3.222656  0.382751 -0.534180 -0.638367  ...       -1.0   \n",
       "\n",
       "   tof_5_v55  tof_5_v56  tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  \\\n",
       "0       87.0      206.0       -1.0      195.0       -1.0       -1.0   \n",
       "1      158.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2      160.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "3      160.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "4      163.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v61  tof_5_v62  tof_5_v63  \n",
       "0       -1.0      111.0       -1.0  \n",
       "1      211.0      187.0      178.0  \n",
       "2       -1.0      197.0      177.0  \n",
       "3       -1.0      197.0      183.0  \n",
       "4       -1.0      200.0      173.0  \n",
       "\n",
       "[5 rows x 336 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>adult_child</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>shoulder_to_wrist_cm</th>\n",
       "      <th>elbow_to_wrist_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165.0</td>\n",
       "      <td>52</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>177.0</td>\n",
       "      <td>52</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject  adult_child  age  sex  handedness  height_cm  \\\n",
       "0  SUBJ_016452            1   25    1           1      165.0   \n",
       "1  SUBJ_055840            0   13    0           1      177.0   \n",
       "\n",
       "   shoulder_to_wrist_cm  elbow_to_wrist_cm  \n",
       "0                    52               23.0  \n",
       "1                    52               27.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_csv(paths.TEST_CSV)\n",
    "df_test_demographics = pd.read_csv(paths.TEST_DEMOGRAPHICS)\n",
    "\n",
    "print(f\"Test dataframe shape: {df_test.shape}\"), sep()\n",
    "print(f\"Test demographics dataframe shape: {df_test_demographics.shape}\")\n",
    "\n",
    "display(df_test.head())\n",
    "display(df_test_demographics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baf7e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 335.69it/s]\n"
     ]
    }
   ],
   "source": [
    "def min_max_scale(arr: np.ndarray) -> np.ndarray:\n",
    "    min_vals = np.nanmin(arr, axis=0)\n",
    "    max_vals = np.nanmax(arr, axis=0)\n",
    "    ranges = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
    "    scaled = (arr - min_vals) / ranges\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def standard_scale(arr: np.ndarray) -> np.ndarray:\n",
    "    means = np.nanmean(arr, axis=0)\n",
    "    stds = np.nanstd(arr, axis=0)\n",
    "    stds = np.where(stds == 0, 1, stds)  # Prevent division by zero for constant columns\n",
    "    scaled = (arr - means) / stds\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def pad_or_truncate(\n",
    "    arr: np.ndarray,\n",
    "    max_length: int = 200,\n",
    "    pad_value: int = 0,\n",
    "    mode: str = \"random\"  # \"regular\" or \"random\"\n",
    ") -> np.ndarray:\n",
    "    L, D = arr.shape\n",
    "\n",
    "    if L > max_length:\n",
    "        return arr[:max_length, :]\n",
    "\n",
    "    elif L < max_length:\n",
    "        if mode == \"regular\":\n",
    "            padding = np.full((max_length - L, D), pad_value)\n",
    "            return np.vstack((arr, padding))\n",
    "        \n",
    "        elif mode == \"random\":\n",
    "            total_padding = max_length - L\n",
    "            pad_start = np.random.randint(0, total_padding + 1)\n",
    "            pad_end = total_padding - pad_start\n",
    "\n",
    "            start_padding = np.full((pad_start, D), pad_value)\n",
    "            end_padding = np.full((pad_end, D), pad_value)\n",
    "\n",
    "            return np.vstack((start_padding, arr, end_padding))\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown mode: {mode}. Use 'regular' or 'random'.\")\n",
    "\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "X_test  = []\n",
    "\n",
    "for sequence_id in tqdm(df_test.sequence_id.unique()):\n",
    "    ds = df_test[df_test[\"sequence_id\"] == sequence_id]\n",
    "    X = ds[imu_cols].values\n",
    "    X = pad_or_truncate(X)\n",
    "    X = np.concatenate((standard_scale(X[:, 0:3]), X[:, 3:]), axis=1)\n",
    "    X = np.where(np.isnan(X), 0.0, X)  # fill NaNs\n",
    "    X_test.append(X)\n",
    "\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42e9a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, config, df: pd.DataFrame, X: np.ndarray\n",
    "    ): \n",
    "        \n",
    "        self.config = config\n",
    "        self.df = df\n",
    "        self.X = X\n",
    "        self.indexes = self.df.sequence_id.unique()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        return len(self.indexes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        sequence_id = self.indexes[index]\n",
    "        X = self.X[index]\n",
    "        output = {\n",
    "            \"X\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"sequence_id\": sequence_id\n",
    "        }\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68828a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(config, df_test, X_test)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.BATCH_SIZE_TEST,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n",
    ")\n",
    "idx = np.random.choice(range(0, len(test_dataset)))\n",
    "cols = imu_cols\n",
    "X = test_dataset[idx][\"X\"]\n",
    "sequence_id = test_dataset[idx][\"sequence_id\"]\n",
    "N = X.shape[0]\n",
    "df = pd.DataFrame(X, columns=cols)\n",
    "df['step'] = range(N)\n",
    "df_melted = df.melt(id_vars='step', var_name='sequence', value_name='value')\n",
    "\n",
    "fig = px.line(\n",
    "    df_melted,\n",
    "    x='step',\n",
    "    y='value',\n",
    "    color='sequence',\n",
    "    title=f\"Sequences for {sequence_id}\",\n",
    "    template='plotly_dark',\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eba52f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2829226\n"
     ]
    }
   ],
   "source": [
    "class Wave_Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, dilation_rates: int, kernel_size: int = 3):\n",
    "        \"\"\"\n",
    "        WaveNet building block.\n",
    "        :param in_channels: number of input channels.\n",
    "        :param out_channels: number of output channels.\n",
    "        :param dilation_rates: how many levels of dilations are used.\n",
    "        :param kernel_size: size of the convolving kernel.\n",
    "        \"\"\"\n",
    "        super(Wave_Block, self).__init__()\n",
    "        self.num_rates = dilation_rates\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        # First conv: (B, in_channels, L) -> (B, out_channels, L)\n",
    "        self.convs.append(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=True)\n",
    "        )\n",
    "        \n",
    "        dilation_rates = [2 ** i for i in range(dilation_rates)]\n",
    "        for dilation_rate in dilation_rates:\n",
    "            # Filter conv: (B, out_channels, L) -> (B, out_channels, L)\n",
    "            self.filter_convs.append(\n",
    "                nn.Conv1d(\n",
    "                    out_channels, out_channels, kernel_size=kernel_size,\n",
    "                    padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate)\n",
    "            )\n",
    "            # Gate conv: (B, out_channels, L) -> (B, out_channels, L)\n",
    "            self.gate_convs.append(\n",
    "                nn.Conv1d(\n",
    "                    out_channels, out_channels, kernel_size=kernel_size,\n",
    "                    padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate)\n",
    "            )\n",
    "            # Residual conv: (B, out_channels, L) -> (B, out_channels, L)\n",
    "            self.convs.append(nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=True))\n",
    "        \n",
    "        for i in range(len(self.convs)):\n",
    "            nn.init.xavier_uniform_(self.convs[i].weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.zeros_(self.convs[i].bias)\n",
    "\n",
    "        for i in range(len(self.filter_convs)):\n",
    "            nn.init.xavier_uniform_(self.filter_convs[i].weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.zeros_(self.filter_convs[i].bias)\n",
    "\n",
    "        for i in range(len(self.gate_convs)):\n",
    "            nn.init.xavier_uniform_(self.gate_convs[i].weight, gain=nn.init.calculate_gain('relu'))\n",
    "            nn.init.zeros_(self.gate_convs[i].bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (B, in_channels, L)\n",
    "        x = self.convs[0](x)  # (B, in_channels, L) -> (B, out_channels, L)\n",
    "        res = x  # res: (B, out_channels, L)\n",
    "        for i in range(self.num_rates):\n",
    "            tanh_out = torch.tanh(self.filter_convs[i](x))  # (B, out_channels, L) -> (B, out_channels, L)\n",
    "            sigmoid_out = torch.sigmoid(self.gate_convs[i](x)) # (B, out_channels, L) -> (B, out_channels, L)\n",
    "            x = tanh_out * sigmoid_out  # (B, out_channels, L) * (B, out_channels, L) -> (B, out_channels, L)\n",
    "            x = self.convs[i + 1](x) # (B, out_channels, L) -> (B, out_channels, L)\n",
    "            res = res + x  # (B, out_channels, L) + (B, out_channels, L) -> (B, out_channels, L)\n",
    "        return res  # (B, out_channels, L)\n",
    "    \n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, input_channels: int = 1, kernel_size: int = 3):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "                Wave_Block(input_channels, 32, 12, kernel_size),   # (B, input_channels, L) -> (B, 8, L)\n",
    "                Wave_Block(32, 64, 8, kernel_size),                # (B, 8, L) -> (B, 16, L)\n",
    "                Wave_Block(64, 128, 4, kernel_size),               # (B, 16, L) -> (B, 32, L)\n",
    "                Wave_Block(128, 256, 1, kernel_size),                # (B, 32, L) -> (B, 64, L)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, L, input_channels) - typical input format\n",
    "        x = x.permute(0, 2, 1)  # (B, L, input_channels) -> (B, input_channels, L)\n",
    "        output = self.model(x)  # (B, input_channels, L) -> (B, 64, L)\n",
    "        return output  # (B, 64, L)\n",
    "\n",
    "\n",
    "class TemporalAttentionPooling(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim=64):\n",
    "        super(TemporalAttentionPooling, self).__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, hidden_dim, kernel_size=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(hidden_dim, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, L)\n",
    "        returns: (B, C)\n",
    "        \"\"\"\n",
    "        # Compute attention scores\n",
    "        attn_scores = self.attn(x)  # (B, 1, L)\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # (B, 1, L)\n",
    "\n",
    "        # Weighted sum over time\n",
    "        weighted = x * attn_weights  # (B, C, L)\n",
    "        pooled = weighted.sum(dim=-1)  # (B, C)\n",
    "\n",
    "        return pooled\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.wavenet1 = WaveNet(input_channels=3)  # WaveNet: (B, input_channels, L) -> (B, 64, L)\n",
    "        self.wavenet2 = WaveNet(input_channels=4)  # WaveNet: (B, input_channels, L) -> (B, 64, L)\n",
    "        self.config = config\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)  # (B, 64, L) -> (B, 64, 1)\n",
    "        self.dropout = 0.2\n",
    "        self.head_1 = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(512, 256), # (B, 64) -> (B, 64)\n",
    "            nn.BatchNorm1d(256),  # (B, 64) -> (B, 64)\n",
    "            nn.ReLU(),  # (B, 64) -> (B, 64)\n",
    "            nn.Dropout(self.dropout),  # (B, 64) -> (B, 64)\n",
    "            nn.Linear(256, num_classes)  # (B, 64) -> (B, num_classes)\n",
    "        )\n",
    "        self.head_2 = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(512, 256), # (B, 64) -> (B, 64)\n",
    "            nn.BatchNorm1d(256),  # (B, 64) -> (B, 64)\n",
    "            nn.ReLU(),  # (B, 64) -> (B, 64)\n",
    "            nn.Dropout(self.dropout),  # (B, 64) -> (B, 64)\n",
    "            nn.Linear(256, 1)  # (B, 64) -> (B, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \"\"\"\n",
    "        # x: (B, L, input_channels) - typical input format\n",
    "        x1 = self.wavenet1(x[:, :, 0:3])  # (B, L, input_channels) -> (B, 64, L)\n",
    "        x1 = self.global_avg_pooling(x1)  # (B, 64, L) -> (B, 64, 1)\n",
    "        x2 = self.wavenet2(x[:, :, 3:])  # (B, L, input_channels) -> (B, 64, L)\n",
    "        x2 = self.global_avg_pooling(x2)  # (B, 64, L) -> (B, 64, 1)\n",
    "        y = torch.concatenate([x1, x2], axis=1) # (B, 128)\n",
    "        z1 = self.head_1(y)  # (B, 64) -> (B, num_classes)\n",
    "        z2 = self.head_2(y)  # (B, 64) -> (B, num_classes)\n",
    "        return z1, z2  # (B, num_classes)\n",
    "\n",
    "model = CustomModel(num_classes=9)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91a86c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1026.25it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m seq_df = test_pl.filter(pl.col(\u001b[33m\"\u001b[39m\u001b[33msequence_id\u001b[39m\u001b[33m\"\u001b[39m) == sequence_id)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Call your model's prediction function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m pred_label = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemographics_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Save the result\u001b[39;00m\n\u001b[32m     68\u001b[39m results.append((sequence_id, pred_label))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(sequence, demographics)\u001b[39m\n\u001b[32m     39\u001b[39m             y_preds = softmax(y_preds).to(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m).numpy()\n\u001b[32m     40\u001b[39m             all_preds.append(y_preds)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m all_preds = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m all_preds = np.argmax(all_preds.mean(axis=\u001b[32m0\u001b[39m)).item()\n\u001b[32m     43\u001b[39m prediction = num_to_label[all_preds]\n",
      "\u001b[31mValueError\u001b[39m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    df_test = sequence.to_pandas()\n",
    "    imu_cols = [\"acc_x\", \"acc_y\", \"acc_z\", \"rot_w\", \"rot_x\", \"rot_y\", \"rot_z\"]\n",
    "    X_test, y_test, y_hard_test = [], [], []\n",
    "    \n",
    "    for sequence_id in tqdm(df_test.sequence_id.unique()):\n",
    "        ds = df_test[df_test[\"sequence_id\"] == sequence_id]\n",
    "        X = ds[imu_cols].values\n",
    "        X = pad_or_truncate(X)\n",
    "        X = np.concatenate((standard_scale(X[:, 0:3]), X[:, 3:]), axis=1)\n",
    "        X = np.where(np.isnan(X), 0.0, X)  # fill NaNs\n",
    "        X_test.append(X)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    model_paths = glob(\"/kaggle/input/cmi-wavenet/*.pth\")\n",
    "    all_preds = []\n",
    "    for model_path in model_paths:\n",
    "        test_dataset = valid_dataset = CustomDataset(config, df_test, X_test)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=config.BATCH_SIZE_TEST,\n",
    "            shuffle=False,\n",
    "            num_workers=config.NUM_WORKERS, \n",
    "            pin_memory=True, drop_last=False\n",
    "        )\n",
    "        model = CustomModel(num_classes=9)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        with tqdm(test_loader, unit=\"test_batch\", desc='Test') as tqdm_test_loader:\n",
    "            for step, batch in enumerate(tqdm_test_loader):\n",
    "                X = batch.pop(\"X\").to(device)\n",
    "                batch_size = X.size(0)\n",
    "                with torch.no_grad():\n",
    "                    y_preds, y_preds_hard = model(X)\n",
    "                y_preds = softmax(y_preds).to('cpu').numpy()\n",
    "                all_preds.append(y_preds)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_preds = np.argmax(all_preds.mean(axis=0)).item()\n",
    "    prediction = num_to_label[all_preds]\n",
    "    return prediction\n",
    "\n",
    "# Load data (update the paths to your local copies)\n",
    "test_csv_path = paths.TEST_CSV\n",
    "test_demo_path = paths.TEST_DEMOGRAPHICS\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "demographics_df = pd.read_csv(test_demo_path)\n",
    "\n",
    "test_pl = pl.from_pandas(test_df)\n",
    "\n",
    "# Run predictions\n",
    "results = []\n",
    "\n",
    "# Loop over each unique sequence_id\n",
    "for sequence_id in test_df['sequence_id'].unique():\n",
    "    # Extract data for this sequence\n",
    "    seq_df = test_pl.filter(pl.col(\"sequence_id\") == sequence_id)\n",
    "\n",
    "    # Call your model's prediction function\n",
    "    pred_label = predict(seq_df, demographics_df)\n",
    "\n",
    "    # Save the result\n",
    "    results.append((sequence_id, pred_label))\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "submission_df = pd.DataFrame(results, columns=[\"sequence_id\", \"prediction\"])\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"✅ Inference complete. Submission saved to submission.csv\")\n",
    "\n",
    "# Launch inference server\n",
    "# inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     inference_server.serve()\n",
    "# else:\n",
    "#     inference_server.run_local_gateway(\n",
    "#         data_paths=(\n",
    "#             '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "#             '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1b32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324a3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "154cb998",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18185225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
