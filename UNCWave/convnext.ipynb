{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf93b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TRAIN = True # bfloat16 or float32 recommended\n",
    "RUN_VALID = False\n",
    "RUN_TEST  = False\n",
    "USE_DEVICE = 'CPU'  # 'GPU'\n",
    "\n",
    "import torch\n",
    "if USE_DEVICE == 'GPU':\n",
    "    if not torch.cuda.is_available() or torch.cuda.device_count() < 2:\n",
    "        raise RuntimeError(\"Requires >= 2 GPUs with CUDA enabled.\")\n",
    "\n",
    "try: \n",
    "    import monai\n",
    "except: \n",
    "    !pip install --no-deps monai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile _cfg.py\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "cfg= SimpleNamespace()\n",
    "cfg.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg.local_rank = 0\n",
    "cfg.seed = 123\n",
    "cfg.subsample = 20 #None\n",
    "data_paths = sorted(glob.glob(\"./datasetfiles/FlatVel_A/data/*.npy\"))\n",
    "label_paths = sorted(glob.glob(\"./datasetfiles/FlatVel_A/model/*.npy\"))\n",
    "cfg.file_pairs = list(zip(sorted(glob.glob(\"./datasetfiles/FlatVel_A/data/*.npy\")), sorted(glob.glob(\"./datasetfiles/FlatVel_A/model/*.npy\"))))\n",
    "# cfg.file_pairs = list(zip(data_paths, label_paths))\n",
    "\n",
    "cfg.backbone = \"convnext_small.fb_in22k_ft_in1k\"\n",
    "cfg.ema = True\n",
    "cfg.ema_decay = 0.99\n",
    "\n",
    "cfg.epochs = 1\n",
    "cfg.batch_size = 8  # 16\n",
    "cfg.batch_size_val = 8 # 16\n",
    "\n",
    "cfg.early_stopping = {\"patience\": 3, \"streak\": 0}\n",
    "cfg.logging_steps = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c262b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile _dataset.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cfg,\n",
    "        file_pairs,  #list of (data_path, label_path) tuples for this specific split\n",
    "        mode = \"train\", \n",
    "    ):\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.file_pairs = file_pairs\n",
    "        \n",
    "        self.data, self.labels = self._load_data_arrays()\n",
    "\n",
    "        self.samples_per_file = 500  # assuming each file has 500 time steps\n",
    "        total_samples_available = len(self.data) * self.samples_per_file\n",
    "\n",
    "        # Subsample logic\n",
    "        subsample = getattr(self.cfg, \"subsample\", None)\n",
    "        self.total_samples = min(subsample, total_samples_available) if subsample else total_samples_available\n",
    "\n",
    "        \n",
    "        # Build list of (file_idx, time_step_idx) pairs\n",
    "        self.index_map = []\n",
    "        for file_idx in range(len(self.data)):\n",
    "            for time_step_idx in range(self.samples_per_file):\n",
    "                self.index_map.append((file_idx, time_step_idx))\n",
    "                if len(self.index_map) >= self.total_samples:\n",
    "                    break\n",
    "            if len(self.index_map) >= self.total_samples:\n",
    "                break\n",
    "\n",
    "    def _load_data_arrays(self, ):\n",
    "               \n",
    "        data_arrays = []\n",
    "        label_arrays = []\n",
    "        mmap_mode = \"r\"\n",
    "\n",
    "        for data_fpath, label_fpath in tqdm(\n",
    "                        self.file_pairs, desc=f\"Loading {self.mode} data (mmap)\",\n",
    "                        disable=self.cfg.local_rank != 0):\n",
    "            try:\n",
    "                # Load the numpy arrays using memory mapping\n",
    "                arr = np.load(data_fpath, mmap_mode=mmap_mode)\n",
    "                lbl = np.load(label_fpath, mmap_mode=mmap_mode)\n",
    "                print(f\"Loaded {data_fpath}: {arr.shape}, {lbl.shape}\")\n",
    "                data_arrays.append(arr)\n",
    "                label_arrays.append(lbl)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: File not found - {data_fpath} r {label_fpath}\", file=sys.stderr)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file pari: {data_fpath}, {label_fpath}\", file=sys.stderr)\n",
    "                print(f\"Error: {e}\", file=sys.stderr)\n",
    "                continue\n",
    "\n",
    "            if self.cfg.local_rank == 0:\n",
    "                print(f\"Finished loading {len(data_arrays)} file pairs for {self.mode} mode.\")\n",
    "\n",
    "        return data_arrays, label_arrays\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # file_idx= idx // 500\n",
    "        # time_step_idx= idx % 500\n",
    "        # self.idx = idx\n",
    "\n",
    "        file_idx, time_step_idx = self.index_map[idx]\n",
    "        \n",
    "        x_full = self.data[file_idx]\n",
    "        y_full = self.labels[file_idx]\n",
    "\n",
    "        # --- Augmentations ---\n",
    "        # Apply augmentations to the full 3D blocks *before* slicing out the time step.\n",
    "        # Make copies after slicing and augmentation to ensure memory safety.\n",
    "        x_augmented = x_full\n",
    "        y_augmented = y_full\n",
    "\n",
    "        # Augs \n",
    "        if self.mode == \"train\":\n",
    "            \n",
    "            # Temporal flip\n",
    "            if np.random.random() < 0.5:\n",
    "                x_augmented = x_full[::-1, :, ::-1] # Time flip (dim 0), Spatial flip (dim 2)\n",
    "                y_augmented = y_full[..., ::-1]  # Spatial flip (dim 2) only\n",
    "\n",
    "        # --- Slicing and Copying ---\n",
    "        # Get the specific time step from the (potentially augmented) full array\n",
    "        # This reslts in a 2D array (Dim1, Dim2)\n",
    "        x_sample = x_augmented[time_step_idx, ...]\n",
    "        y_sample = y_augmented[time_step_idx, ...]\n",
    "\n",
    "        # make copies to return independent arrays/tensors.\n",
    "        # This is important especially with mmap and multiprocessing DataLoaders.\n",
    "        x_sample = x_sample.copy()\n",
    "        y_sample = y_sample.copy()\n",
    "\n",
    "        x_tensor = torch.from_numpy(x_sample).float()\n",
    "        y_tensor = torch.from_numpy(y_sample).float()\n",
    "        \n",
    "        return x_tensor, y_tensor\n",
    "\n",
    "    def __len__(self, ):\n",
    "        return self.total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cdf5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile _model.py\n",
    "\n",
    "from copy import deepcopy\n",
    "from types import MethodType\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "from timm.models.convnext import ConvNeXtBlock\n",
    "\n",
    "from monai.networks.blocks import UpSample, SubpixelUpsample\n",
    "\n",
    "####################\n",
    "## EMA + Ensemble ##\n",
    "####################\n",
    "\n",
    "class ModelEMA(nn.Module):\n",
    "    def __init__(self, model, decay=0.99, device=None):\n",
    "        super().__init__()\n",
    "        self.module = deepcopy(model)\n",
    "        self.module.eval()\n",
    "        self.decay = decay\n",
    "        self.device = device\n",
    "        if self.device is not None:\n",
    "            self.module.to(device=device)\n",
    "\n",
    "    def _update(self, model, update_fn):\n",
    "        with torch.no_grad():\n",
    "            for ema_v, model_v in zip(self.module.state_dict().values(), model.state_dict().values()):\n",
    "                if self.device is not None:\n",
    "                    model_v = model_v.to(device=self.device)\n",
    "                ema_v.copy_(update_fn(ema_v, model_v))\n",
    "\n",
    "    def update(self, model):\n",
    "        self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
    "\n",
    "    def set(self, model):\n",
    "        self._update(model, update_fn=lambda e, m: m)\n",
    "\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models).eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = None\n",
    "        \n",
    "        for m in self.models:\n",
    "            logits= m(x)\n",
    "            \n",
    "            if output is None:\n",
    "                output = logits\n",
    "            else:\n",
    "                output += logits\n",
    "                \n",
    "        output /= len(self.models)\n",
    "        return output\n",
    "        \n",
    "\n",
    "#############\n",
    "## Decoder ##\n",
    "#############\n",
    "\n",
    "class ConvBnAct2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        padding: int = 0,\n",
    "        stride: int = 1,\n",
    "        norm_layer: nn.Module = nn.Identity,\n",
    "        act_layer: nn.Module = nn.ReLU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv= nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride, \n",
    "            padding=padding, \n",
    "            bias=False,\n",
    "        )\n",
    "        self.norm = norm_layer(out_channels) if norm_layer != nn.Identity else nn.Identity()\n",
    "        self.act= act_layer(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SCSEModule2d(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.cSE = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.sSE = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 1, 1), \n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.cSE(x) + x * self.sSE(x)\n",
    "\n",
    "class Attention2d(nn.Module):\n",
    "    def __init__(self, name, **params):\n",
    "        super().__init__()\n",
    "        if name is None:\n",
    "            self.attention = nn.Identity(**params)\n",
    "        elif name == \"scse\":\n",
    "            self.attention = SCSEModule2d(**params)\n",
    "        else:\n",
    "            raise ValueError(\"Attention {} is not implemented\".format(name))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.attention(x)\n",
    "\n",
    "class DecoderBlock2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        skip_channels,\n",
    "        out_channels,\n",
    "        norm_layer: nn.Module = nn.Identity,\n",
    "        attention_type: str = None,\n",
    "        intermediate_conv: bool = False,\n",
    "        upsample_mode: str = \"deconv\",\n",
    "        scale_factor: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Upsample block\n",
    "        if upsample_mode == \"pixelshuffle\":\n",
    "            self.upsample= SubpixelUpsample(\n",
    "                spatial_dims= 2,\n",
    "                in_channels= in_channels,\n",
    "                scale_factor= scale_factor,\n",
    "            )\n",
    "        else:\n",
    "            self.upsample = UpSample(\n",
    "                spatial_dims= 2,\n",
    "                in_channels= in_channels,\n",
    "                out_channels= in_channels,\n",
    "                scale_factor= scale_factor,\n",
    "                mode= upsample_mode,\n",
    "            )\n",
    "\n",
    "        if intermediate_conv:\n",
    "            k= 3\n",
    "            c= skip_channels if skip_channels != 0 else in_channels\n",
    "            self.intermediate_conv = nn.Sequential(\n",
    "                ConvBnAct2d(c, c, k, k//2),\n",
    "                ConvBnAct2d(c, c, k, k//2),\n",
    "                )\n",
    "        else:\n",
    "            self.intermediate_conv= None\n",
    "\n",
    "        self.attention1 = Attention2d(\n",
    "            name= attention_type, \n",
    "            in_channels= in_channels + skip_channels,\n",
    "            )\n",
    "\n",
    "        self.conv1 = ConvBnAct2d(\n",
    "            in_channels + skip_channels,\n",
    "            out_channels,\n",
    "            kernel_size= 3,\n",
    "            padding= 1,\n",
    "            norm_layer= norm_layer,\n",
    "        )\n",
    "\n",
    "        self.conv2 = ConvBnAct2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size= 3,\n",
    "            padding= 1,\n",
    "            norm_layer= norm_layer,\n",
    "        )\n",
    "        self.attention2 = Attention2d(\n",
    "            name= attention_type, \n",
    "            in_channels= out_channels,\n",
    "            )\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        if self.intermediate_conv is not None:\n",
    "            if skip is not None:\n",
    "                skip = self.intermediate_conv(skip)\n",
    "            else:\n",
    "                x = self.intermediate_conv(x)\n",
    "\n",
    "        if skip is not None:\n",
    "            # print(x.shape, skip.shape)\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = self.attention1(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.attention2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UnetDecoder2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Unet decoder.\n",
    "    Source: https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_channels: tuple[int],\n",
    "        skip_channels: tuple[int] = None,\n",
    "        decoder_channels: tuple = (256, 128, 64, 32),\n",
    "        scale_factors: tuple = (2,2,2,2),\n",
    "        norm_layer: nn.Module = nn.Identity,\n",
    "        attention_type: str = None,\n",
    "        intermediate_conv: bool = False,\n",
    "        upsample_mode: str = \"deconv\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        if len(encoder_channels) == 4:\n",
    "            decoder_channels= decoder_channels[1:]\n",
    "        self.decoder_channels= decoder_channels\n",
    "        \n",
    "        if skip_channels is None:\n",
    "            skip_channels= list(encoder_channels[1:]) + [0]\n",
    "\n",
    "        # Build decoder blocks\n",
    "        in_channels= [encoder_channels[0]] + list(decoder_channels[:-1])\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        for i, (ic, sc, dc) in enumerate(zip(in_channels, skip_channels, decoder_channels)):\n",
    "            # print(i, ic, sc, dc)\n",
    "            self.blocks.append(\n",
    "                DecoderBlock2d(\n",
    "                    ic, sc, dc, \n",
    "                    norm_layer= norm_layer,\n",
    "                    attention_type= attention_type,\n",
    "                    intermediate_conv= intermediate_conv,\n",
    "                    upsample_mode= upsample_mode,\n",
    "                    scale_factor= scale_factors[i],\n",
    "                    )\n",
    "            )\n",
    "\n",
    "    def forward(self, feats: list[torch.Tensor]):\n",
    "        res= [feats[0]]\n",
    "        feats= feats[1:]\n",
    "\n",
    "        # Decoder blocks\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            skip= feats[i] if i < len(feats) else None\n",
    "            res.append(\n",
    "                b(res[-1], skip=skip),\n",
    "                )\n",
    "            \n",
    "        return res\n",
    "\n",
    "class SegmentationHead2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        scale_factor: tuple[int] = (2,2),\n",
    "        kernel_size: int = 3,\n",
    "        mode: str = \"nontrainable\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv= nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size= kernel_size,\n",
    "            padding= kernel_size//2\n",
    "        )\n",
    "        self.upsample = UpSample(\n",
    "            spatial_dims= 2,\n",
    "            in_channels= out_channels,\n",
    "            out_channels= out_channels,\n",
    "            scale_factor= scale_factor,\n",
    "            mode= mode,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "#############\n",
    "## Encoder ##\n",
    "#############\n",
    "\n",
    "def _convnext_block_forward(self, x):\n",
    "    shortcut = x\n",
    "    x = self.conv_dw(x)\n",
    "\n",
    "    if self.use_conv_mlp:\n",
    "        x = self.norm(x)\n",
    "        x = self.mlp(x)\n",
    "    else:\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = x.contiguous()\n",
    "        x = self.mlp(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.contiguous()\n",
    "\n",
    "    if self.gamma is not None:\n",
    "        x = x * self.gamma.reshape(1, -1, 1, 1)\n",
    "\n",
    "    x = self.drop_path(x) + self.shortcut(shortcut)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: str,\n",
    "        pretrained: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.backbone= timm.create_model(\n",
    "            backbone,\n",
    "            in_chans= 5,\n",
    "            pretrained= pretrained,\n",
    "            features_only= True,\n",
    "            drop_path_rate=0.0,\n",
    "            )\n",
    "        ecs= [_[\"num_chs\"] for _ in self.backbone.feature_info][::-1]\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder= UnetDecoder2d(\n",
    "            encoder_channels= ecs,\n",
    "        )\n",
    "\n",
    "        self.seg_head= SegmentationHead2d(\n",
    "            in_channels= self.decoder.decoder_channels[-1],\n",
    "            out_channels= 1,\n",
    "            scale_factor= 1,\n",
    "        )\n",
    "        \n",
    "        self._update_stem(backbone)\n",
    "        \n",
    "        self.replace_activations(self.backbone, log=True)\n",
    "        self.replace_norms(self.backbone, log=True)\n",
    "        self.replace_forwards(self.backbone, log=True)\n",
    "\n",
    "    def _update_stem(self, backbone):\n",
    "        if backbone.startswith(\"convnext\"):\n",
    "\n",
    "            # Update stride\n",
    "            self.backbone.stem_0.stride = (4, 1)\n",
    "            self.backbone.stem_0.padding = (0, 2)\n",
    "\n",
    "            # Duplicate stem layer (to downsample height)\n",
    "            with torch.no_grad():\n",
    "                w = self.backbone.stem_0.weight\n",
    "                new_conv= nn.Conv2d(w.shape[0], w.shape[0], kernel_size=(4, 4), stride=(4, 1), padding=(0, 1))\n",
    "                new_conv.weight.copy_(w.repeat(1, (128//w.shape[1])+1, 1, 1)[:, :new_conv.weight.shape[1], :, :])\n",
    "                new_conv.bias.copy_(self.backbone.stem_0.bias)\n",
    "\n",
    "            self.backbone.stem_0= nn.Sequential(\n",
    "                nn.ReflectionPad2d((1,1,80,80)),\n",
    "                self.backbone.stem_0,\n",
    "                new_conv,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Custom striding not implemented.\")\n",
    "        pass\n",
    "\n",
    "    def replace_activations(self, module, log=False):\n",
    "        if log:\n",
    "            print(f\"Replacing all activations with GELU...\")\n",
    "        \n",
    "        # Apply activations\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, (\n",
    "                nn.ReLU, nn.LeakyReLU, nn.Mish, nn.Sigmoid, \n",
    "                nn.Tanh, nn.Softmax, nn.Hardtanh, nn.ELU, \n",
    "                nn.SELU, nn.PReLU, nn.CELU, nn.GELU, nn.SiLU,\n",
    "            )):\n",
    "                setattr(module, name, nn.GELU())\n",
    "            else:\n",
    "                self.replace_activations(child)\n",
    "\n",
    "    def replace_norms(self, mod, log=False):\n",
    "        if log:\n",
    "            print(f\"Replacing all norms with InstanceNorm...\")\n",
    "            \n",
    "        for name, c in mod.named_children():\n",
    "\n",
    "            # Get feature size\n",
    "            n_feats= None\n",
    "            if isinstance(c, (nn.BatchNorm2d, nn.InstanceNorm2d)):\n",
    "                n_feats= c.num_features\n",
    "            elif isinstance(c, (nn.GroupNorm,)):\n",
    "                n_feats= c.num_channels\n",
    "            elif isinstance(c, (nn.LayerNorm,)):\n",
    "                n_feats= c.normalized_shape[0]\n",
    "\n",
    "            if n_feats is not None:\n",
    "                new = nn.InstanceNorm2d(\n",
    "                    n_feats,\n",
    "                    affine=True,\n",
    "                    )\n",
    "                setattr(mod, name, new)\n",
    "            else:\n",
    "                self.replace_norms(c)\n",
    "\n",
    "    def replace_forwards(self, mod, log=False):\n",
    "        if log:\n",
    "            print(f\"Replacing forward functions...\")\n",
    "            \n",
    "        for name, c in mod.named_children():\n",
    "            if isinstance(c, ConvNeXtBlock):\n",
    "                c.forward = MethodType(_convnext_block_forward, c)\n",
    "            else:\n",
    "                self.replace_forwards(c)\n",
    "\n",
    "        \n",
    "    def proc_flip(self, x_in):\n",
    "        x_in= torch.flip(x_in, dims=[-3, -1])\n",
    "        x= self.backbone(x_in)\n",
    "        x= x[::-1]\n",
    "\n",
    "        # Decoder\n",
    "        x= self.decoder(x)\n",
    "        x_seg= self.seg_head(x[-1])\n",
    "        x_seg= x_seg[..., 1:-1, 1:-1]\n",
    "        x_seg= torch.flip(x_seg, dims=[-1])\n",
    "        x_seg= x_seg * 1500 + 3000\n",
    "        return x_seg\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x= batch\n",
    "\n",
    "        # Encoder\n",
    "        x_in = x\n",
    "        x= self.backbone(x)\n",
    "        # print([_.shape for _ in x])\n",
    "        x= x[::-1]\n",
    "\n",
    "        # Decoder\n",
    "        x= self.decoder(x)\n",
    "        # print([_.shape for _ in x])\n",
    "        x_seg= self.seg_head(x[-1])\n",
    "        x_seg= x_seg[..., 1:-1, 1:-1]\n",
    "        x_seg= x_seg * 1500 + 3000\n",
    "    \n",
    "        if self.training:\n",
    "            return x_seg\n",
    "        else:\n",
    "            p1 = self.proc_flip(x_in)\n",
    "            x_seg = torch.mean(torch.stack([x_seg, p1]), dim=0)\n",
    "            return x_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14240622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile _utils.py\n",
    "\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training code for CPU\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "# Remove or comment out if you don't have it (but typically comes with pytorch)\n",
    "# import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset # Use standard DataLoader/Dataset\n",
    "# from torch.utils.data.distributed import DistributedSampler # Removed\n",
    "# from torch.cuda.amp import autocast, GradScaler # Removed\n",
    "from tqdm import tqdm\n",
    "from _cfg import cfg\n",
    "\n",
    "cfg.local_rank = 0\n",
    "cfg.world_size = 1\n",
    "cfg.device = 'cpu' # Ensure device is set to CPU\n",
    "\n",
    "def set_seed(seed=cfg.seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # Removed torch.cuda.manual_seed, torch.backends.cudnn settings\n",
    "\n",
    "data_paths = sorted(glob.glob(\"./datasetfiles/FlatVel_A/data/*.npy\"))\n",
    "label_paths = sorted(glob.glob(\"./datasetfiles/FlatVel_A/model/*.npy\"))\n",
    "file_pairs = list(zip(data_paths, label_paths))\n",
    "\n",
    "\n",
    "\n",
    "# Ensure device is set to 'cpu' in cfg for clarity in this modified version\n",
    "cfg.device = 'cpu'\n",
    "\n",
    "# ========== Datasets / Dataloaders ==========\n",
    "if cfg.local_rank == 0:\n",
    "    print(\"=\"*25)\n",
    "    print(\"Loading data..\")\n",
    "\n",
    "print(f\"file_pairs: {cfg.file_pairs[:2]}\")\n",
    "print(f\"Type of first element: {type(cfg.file_pairs[0])}\")\n",
    "train_ds = CustomDataset(cfg=cfg, file_pairs=file_pairs, mode=\"train\")\n",
    "# Replaced DistributedSampler with standard DataLoader and shuffle\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size= cfg.batch_size,\n",
    "    num_workers= 0, #4,\n",
    "    shuffle=True, # Add shuffle for training\n",
    ")\n",
    "\n",
    "valid_ds = CustomDataset(cfg=cfg, file_pairs=file_pairs, mode=\"valid\")\n",
    "# Replaced DistributedSampler with standard DataLoader\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "    valid_ds,\n",
    "    batch_size= cfg.batch_size_val,\n",
    "    num_workers= 0, #4,\n",
    "    shuffle=False, # No shuffle for validation\n",
    ")\n",
    "\n",
    "x, y = train_ds[0]\n",
    "print(\"Sample shape:\", x.shape, y.shape)\n",
    "# ========== Model / Optim ==========\n",
    "model = Net(backbone=cfg.backbone)\n",
    "# Removed .to(cfg.local_rank) - models are on CPU by default\n",
    "\n",
    "if cfg.ema:\n",
    "    if cfg.local_rank == 0:\n",
    "        print(\"Initializing EMA model..\")\n",
    "    # Set device explicitly to 'cpu' for EMA\n",
    "    ema_model = ModelEMA(\n",
    "        model,\n",
    "        decay=cfg.ema_decay,\n",
    "        device='cpu',\n",
    "    )\n",
    "else:\n",
    "    ema_model = None\n",
    "\n",
    "# Removed DistributedDataParallel wrap - use the base model directly\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Removed GradScaler - not needed for CPU or non-mixed precision\n",
    "\n",
    "# ========== Training ==========\n",
    "if cfg.local_rank == 0:\n",
    "    print(\"=\"*25)\n",
    "    # Adjusted print message\n",
    "    print(\"Running on CPU (single process).\")\n",
    "    print(\"=\"*25)\n",
    "\n",
    "best_loss= 1_000_000\n",
    "val_loss= 1_000_000 # Initialize val_loss for logging on epoch 0\n",
    "\n",
    "for epoch in range(0, cfg.epochs+1):\n",
    "    if epoch != 0: # Skip epoch 0 training loop\n",
    "        tstart= time.time()\n",
    "        # Removed sampler.set_epoch - not needed for standard DataLoader\n",
    "\n",
    "        # Train loop\n",
    "        model.train()\n",
    "        total_loss = []\n",
    "        # tqdm for train loop only on rank 0\n",
    "        train_loop = tqdm(train_dl, disable=cfg.local_rank != 0, desc=f\"Epoch {epoch} Training\")\n",
    "        for i, (x, y) in enumerate(train_loop):\n",
    "            # Removed .to(cfg.local_rank) - data is already on CPU\n",
    "            # Removed autocast context\n",
    "\n",
    "            logits = model(x)\n",
    "\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            # Replaced scaler steps with standard backprop and optimizer step\n",
    "            loss.backward()\n",
    "            # Removed scaler.unscale_\n",
    "            optimizer.step()\n",
    "            # Removed scaler.update\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            if ema_model is not None:\n",
    "                ema_model.update(model)\n",
    "\n",
    "            # Logging within the loop (simplified for single process)\n",
    "            if cfg.local_rank == 0 and (len(total_loss) >= cfg.logging_steps or i == len(train_dl)-1 or i == 0):\n",
    "                current_train_loss_avg = np.mean(total_loss[-cfg.logging_steps:]) # Avg of last logging steps\n",
    "                if i == 0: current_train_loss_avg = total_loss[0] # Handle first step log\n",
    "                train_loop.set_postfix(train_mae=f\"{current_train_loss_avg:.4f}\", val_mae=f\"{val_loss:.4f}\")\n",
    "                # Original logging format (can keep if preferred, but tqdm is better)\n",
    "                # if (len(total_loss) % cfg.logging_steps == 0 or i == len(train_dl)-1):\n",
    "                #    train_loss_avg = np.mean(total_loss)\n",
    "                #    print(\"Epoch {}:     Train MAE: {:.2f}     Val MAE: {:.2f}     Time: {}     Step: {}/{}\".format(\n",
    "                #        epoch,\n",
    "                #        train_loss_avg,\n",
    "                #        val_loss,\n",
    "                #        format_time(time.time() - tstart),\n",
    "                #        i+1,\n",
    "                #        len(train_dl), # Fix len(train_dl)+1 -> len(train_dl)\n",
    "                #    ))\n",
    "\n",
    "        # Log average train loss after epoch\n",
    "        if cfg.local_rank == 0:\n",
    "                train_loss_avg_epoch = np.mean(total_loss)\n",
    "                print(f\"\\nEpoch {epoch} Training finished. Avg Train MAE: {train_loss_avg_epoch:.4f}\")\n",
    "\n",
    "\n",
    "    # ========== Valid ==========\n",
    "    model.eval()\n",
    "    val_logits = []\n",
    "    val_targets = []\n",
    "    # tqdm for validation loop on rank 0\n",
    "    valid_loop = tqdm(valid_dl, disable=cfg.local_rank != 0, desc=f\"Epoch {epoch} Validation\")\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loop:\n",
    "            # Removed .to(cfg.local_rank) - data is already on CPU\n",
    "\n",
    "            # Removed autocast context\n",
    "            if ema_model is not None:\n",
    "                # Access the underlying model from EMA wrapper\n",
    "                # out = ema_model.ema_model(x) # Or ema_model.model(x) depending on EMA implementation\n",
    "                out = ema_model.module(x) # Or ema_model.model(x) depending on EMA implementation\n",
    "            else:\n",
    "                out = model(x)\n",
    "\n",
    "            val_logits.append(out.cpu())\n",
    "            val_targets.append(y.cpu())\n",
    "\n",
    "        val_logits= torch.cat(val_logits, dim=0)\n",
    "        val_targets= torch.cat(val_targets, dim=0)\n",
    "\n",
    "        # Calculate loss directly (no all_reduce needed)\n",
    "        val_loss = criterion(val_logits, val_targets).item()\n",
    "\n",
    "    # Removed Gather loss (all_reduce) - loss is already the final val_loss\n",
    "\n",
    "    # ========== Weights / Early stopping ==========\n",
    "    # Removed stop_train tensor and broadcast - handled directly in single process\n",
    "    if cfg.local_rank == 0: # This block runs because local_rank is 0\n",
    "        es= cfg.early_stopping # Ensure es is a local variable\n",
    "        if val_loss < best_loss:\n",
    "            print(f\"\\nNew best: {best_loss:.4f} -> {val_loss:.4f}\") # Improved formatting\n",
    "            print(\"Saved weights..\")\n",
    "            best_loss = val_loss\n",
    "            if ema_model is not None:\n",
    "                # Save the state dict of the EMA model's actual weights\n",
    "                # Assuming ModelEMA stores the EMA model internally, e.g., as .ema_model\n",
    "                # Adjust this line based on your ModelEMA implementation\n",
    "                torch.save(ema_model.module.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "            else:\n",
    "                torch.save(model.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "\n",
    "            es[\"streak\"] = 0\n",
    "        else:\n",
    "            es[\"streak\"] += 1\n",
    "            print(f\"\\nValidation loss did not improve. Streak: {es['streak']}/{es['patience']}\") # Added log\n",
    "            if es[\"streak\"] > es[\"patience\"]:\n",
    "                print(\"Ending training (early_stopping).\")\n",
    "                # Direct return for early stopping\n",
    "                # return # Exit the main function\n",
    "\n",
    "    # Added a short delay to allow print statements to flush if needed (less critical for CPU)\n",
    "    # time.sleep(1) # Optional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306c7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19476b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training code for CPU\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time, glob\n",
    "import numpy as np\n",
    "import torch\n",
    "# Remove or comment out if you don't have it (but typically comes with pytorch)\n",
    "# import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset # Use standard DataLoader/Dataset\n",
    "# from torch.utils.data.distributed import DistributedSampler # Removed\n",
    "# from torch.cuda.amp import autocast, GradScaler # Removed\n",
    "from tqdm import tqdm\n",
    "from _cfg import cfg\n",
    "\n",
    "def set_seed(seed=cfg.seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # Removed torch.cuda.manual_seed, torch.backends.cudnn settings\n",
    "\n",
    "data_paths = sorted(glob.glob(\"./datasetfiles/FlatVel_A/data/*.npy\"))\n",
    "label_paths = sorted(glob.glob(\"./datasetfiles/FlatVel_A/model/*.npy\"))\n",
    "file_pairs = list(zip(data_paths, label_paths))\n",
    "\n",
    "def main(cfg):\n",
    "\n",
    "    # Ensure device is set to 'cpu' in cfg for clarity in this modified version\n",
    "    cfg.device = 'cpu'\n",
    "\n",
    "    # ========== Datasets / Dataloaders ==========\n",
    "    if cfg.local_rank == 0:\n",
    "        print(\"=\"*25)\n",
    "        print(\"Loading data..\")\n",
    "\n",
    "    print(f\"file_pairs: {cfg.file_pairs[:2]}\")\n",
    "    print(f\"Type of first element: {type(cfg.file_pairs[0])}\")\n",
    "    train_ds = CustomDataset(cfg=cfg, file_pairs=file_pairs, mode=\"train\")\n",
    "    # Replaced DistributedSampler with standard DataLoader and shuffle\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size= cfg.batch_size,\n",
    "        num_workers= 0, #4,\n",
    "        shuffle=True, # Add shuffle for training\n",
    "    )\n",
    "\n",
    "    valid_ds = CustomDataset(cfg=cfg, file_pairs=file_pairs, mode=\"valid\")\n",
    "    # Replaced DistributedSampler with standard DataLoader\n",
    "    valid_dl = torch.utils.data.DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size= cfg.batch_size_val,\n",
    "        num_workers= 0, #4,\n",
    "        shuffle=False, # No shuffle for validation\n",
    "    )\n",
    "\n",
    "    # ========== Model / Optim ==========\n",
    "    model = Net(backbone=cfg.backbone)\n",
    "    # Removed .to(cfg.local_rank) - models are on CPU by default\n",
    "\n",
    "    if cfg.ema:\n",
    "        if cfg.local_rank == 0:\n",
    "            print(\"Initializing EMA model..\")\n",
    "        # Set device explicitly to 'cpu' for EMA\n",
    "        ema_model = ModelEMA(\n",
    "            model,\n",
    "            decay=cfg.ema_decay,\n",
    "            device='cpu',\n",
    "        )\n",
    "    else:\n",
    "        ema_model = None\n",
    "\n",
    "    # Removed DistributedDataParallel wrap - use the base model directly\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    # Removed GradScaler - not needed for CPU or non-mixed precision\n",
    "\n",
    "    # ========== Training ==========\n",
    "    if cfg.local_rank == 0:\n",
    "        print(\"=\"*25)\n",
    "        # Adjusted print message\n",
    "        print(\"Running on CPU (single process).\")\n",
    "        print(\"=\"*25)\n",
    "\n",
    "    best_loss= 1_000_000\n",
    "    val_loss= 1_000_000 # Initialize val_loss for logging on epoch 0\n",
    "\n",
    "    for epoch in range(0, cfg.epochs+1):\n",
    "        if epoch != 0: # Skip epoch 0 training loop\n",
    "            tstart= time.time()\n",
    "            # Removed sampler.set_epoch - not needed for standard DataLoader\n",
    "\n",
    "            # Train loop\n",
    "            model.train()\n",
    "            total_loss = []\n",
    "            # tqdm for train loop only on rank 0\n",
    "            train_loop = tqdm(train_dl, disable=cfg.local_rank != 0, desc=f\"Epoch {epoch} Training\")\n",
    "            for i, (x, y) in enumerate(train_loop):\n",
    "                # Removed .to(cfg.local_rank) - data is already on CPU\n",
    "                # Removed autocast context\n",
    "\n",
    "                logits = model(x)\n",
    "\n",
    "                loss = criterion(logits, y)\n",
    "\n",
    "                # Replaced scaler steps with standard backprop and optimizer step\n",
    "                loss.backward()\n",
    "                # Removed scaler.unscale_\n",
    "                optimizer.step()\n",
    "                # Removed scaler.update\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                total_loss.append(loss.item())\n",
    "\n",
    "                if ema_model is not None:\n",
    "                    ema_model.update(model)\n",
    "\n",
    "                # Logging within the loop (simplified for single process)\n",
    "                if cfg.local_rank == 0 and (len(total_loss) >= cfg.logging_steps or i == len(train_dl)-1 or i == 0):\n",
    "                    current_train_loss_avg = np.mean(total_loss[-cfg.logging_steps:]) # Avg of last logging steps\n",
    "                    if i == 0: current_train_loss_avg = total_loss[0] # Handle first step log\n",
    "                    train_loop.set_postfix(train_mae=f\"{current_train_loss_avg:.4f}\", val_mae=f\"{val_loss:.4f}\")\n",
    "                    # Original logging format (can keep if preferred, but tqdm is better)\n",
    "                    # if (len(total_loss) % cfg.logging_steps == 0 or i == len(train_dl)-1):\n",
    "                    #    train_loss_avg = np.mean(total_loss)\n",
    "                    #    print(\"Epoch {}:     Train MAE: {:.2f}     Val MAE: {:.2f}     Time: {}     Step: {}/{}\".format(\n",
    "                    #        epoch,\n",
    "                    #        train_loss_avg,\n",
    "                    #        val_loss,\n",
    "                    #        format_time(time.time() - tstart),\n",
    "                    #        i+1,\n",
    "                    #        len(train_dl), # Fix len(train_dl)+1 -> len(train_dl)\n",
    "                    #    ))\n",
    "\n",
    "            # Log average train loss after epoch\n",
    "            if cfg.local_rank == 0:\n",
    "                 train_loss_avg_epoch = np.mean(total_loss)\n",
    "                 print(f\"\\nEpoch {epoch} Training finished. Avg Train MAE: {train_loss_avg_epoch:.4f}\")\n",
    "\n",
    "\n",
    "        # ========== Valid ==========\n",
    "        model.eval()\n",
    "        val_logits = []\n",
    "        val_targets = []\n",
    "        # tqdm for validation loop on rank 0\n",
    "        valid_loop = tqdm(valid_dl, disable=cfg.local_rank != 0, desc=f\"Epoch {epoch} Validation\")\n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_loop:\n",
    "                # Removed .to(cfg.local_rank) - data is already on CPU\n",
    "\n",
    "                # Removed autocast context\n",
    "                if ema_model is not None:\n",
    "                    # Access the underlying model from EMA wrapper\n",
    "                    # out = ema_model.ema_model(x) # Or ema_model.model(x) depending on EMA implementation\n",
    "                    out = ema_model.module(x) # Or ema_model.model(x) depending on EMA implementation\n",
    "                else:\n",
    "                    out = model(x)\n",
    "\n",
    "                val_logits.append(out.cpu())\n",
    "                val_targets.append(y.cpu())\n",
    "\n",
    "            val_logits= torch.cat(val_logits, dim=0)\n",
    "            val_targets= torch.cat(val_targets, dim=0)\n",
    "\n",
    "            # Calculate loss directly (no all_reduce needed)\n",
    "            val_loss = criterion(val_logits, val_targets).item()\n",
    "\n",
    "        # Removed Gather loss (all_reduce) - loss is already the final val_loss\n",
    "\n",
    "        # ========== Weights / Early stopping ==========\n",
    "        # Removed stop_train tensor and broadcast - handled directly in single process\n",
    "        if cfg.local_rank == 0: # This block runs because local_rank is 0\n",
    "            es= cfg.early_stopping # Ensure es is a local variable\n",
    "            if val_loss < best_loss:\n",
    "                print(f\"\\nNew best: {best_loss:.4f} -> {val_loss:.4f}\") # Improved formatting\n",
    "                print(\"Saved weights..\")\n",
    "                best_loss = val_loss\n",
    "                if ema_model is not None:\n",
    "                    # Save the state dict of the EMA model's actual weights\n",
    "                    # Assuming ModelEMA stores the EMA model internally, e.g., as .ema_model\n",
    "                    # Adjust this line based on your ModelEMA implementation\n",
    "                    torch.save(ema_model.module.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "\n",
    "                es[\"streak\"] = 0\n",
    "            else:\n",
    "                es[\"streak\"] += 1\n",
    "                print(f\"\\nValidation loss did not improve. Streak: {es['streak']}/{es['patience']}\") # Added log\n",
    "                if es[\"streak\"] > es[\"patience\"]:\n",
    "                    print(\"Ending training (early_stopping).\")\n",
    "                    # Direct return for early stopping\n",
    "                    return # Exit the main function\n",
    "\n",
    "        # Added a short delay to allow print statements to flush if needed (less critical for CPU)\n",
    "        # time.sleep(1) # Optional\n",
    "\n",
    "    return # End of epochs reached\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Simplified init for single-process CPU\n",
    "    # Removed GPU specs check and setup/cleanup calls\n",
    "    # Removed time.sleep for synchronization\n",
    "\n",
    "    # Set rank and world_size for the single process\n",
    "    cfg.local_rank = 0\n",
    "    cfg.world_size = 1\n",
    "    cfg.device = 'cpu' # Ensure device is set to CPU\n",
    "\n",
    "    print(f\"Starting single-process CPU test (Rank: {cfg.local_rank}, World size: {cfg.world_size})\")\n",
    "\n",
    "    # Seed (CPU parts kept)\n",
    "    set_seed(cfg.seed + cfg.local_rank)\n",
    "\n",
    "    # Run main training/validation loop\n",
    "    main(cfg)\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    # Removed cleanup call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25031d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd0dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "###################\n",
    "###################\n",
    "%%writefile _train.py\n",
    "\n",
    "####  for GPU  ####\n",
    "###################\n",
    "###################\n",
    "\n",
    "import os\n",
    "import time \n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from _cfg import cfg\n",
    "from _dataset import CustomDataset\n",
    "from _model import ModelEMA, Net\n",
    "from _utils import format_time\n",
    "\n",
    "def set_seed(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def setup(rank, world_size, device=NONE):\n",
    "    if device is None:\n",
    "        devide = USE_DEVICE\n",
    "\n",
    "    if device.upper() == 'CPU':\n",
    "        dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "    if device.upper() =='GPU':\n",
    "        torch.cuda.set_device(rank)\n",
    "        dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown device type: {device}\")\n",
    "    return\n",
    "\n",
    "def cleanup():\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group()\n",
    "    return\n",
    "\n",
    "def main(cfg):\n",
    "\n",
    "    # ========== Datasets / Dataloaders ==========\n",
    "    if cfg.local_rank == 0:\n",
    "        print(\"=\"*25)\n",
    "        print(\"Loading data..\")\n",
    "    train_ds = CustomDataset(cfg=cfg, mode=\"train\")\n",
    "    sampler= DistributedSampler(\n",
    "        train_ds, \n",
    "        num_replicas=cfg.world_size, \n",
    "        rank=cfg.local_rank,\n",
    "    )\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_ds, \n",
    "        sampler= sampler,\n",
    "        batch_size= cfg.batch_size, \n",
    "        num_workers= 4,\n",
    "    )\n",
    "    \n",
    "    valid_ds = CustomDataset(cfg=cfg, mode=\"valid\")\n",
    "    sampler= DistributedSampler(\n",
    "        valid_ds, \n",
    "        num_replicas=cfg.world_size, \n",
    "        rank=cfg.local_rank,\n",
    "    )\n",
    "    valid_dl = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        sampler= sampler,\n",
    "        batch_size= cfg.batch_size_val, \n",
    "        num_workers= 4,\n",
    "    )\n",
    "\n",
    "    # ========== Model / Optim ==========\n",
    "    model = Net(backbone=cfg.backbone)\n",
    "    model= model.to(cfg.local_rank)\n",
    "    if cfg.ema:\n",
    "        if cfg.local_rank == 0:\n",
    "            print(\"Initializing EMA model..\")\n",
    "        ema_model = ModelEMA(\n",
    "            model, \n",
    "            decay=cfg.ema_decay, \n",
    "            device=cfg.local_rank,\n",
    "        )\n",
    "    else:\n",
    "        ema_model = None\n",
    "    model= DistributedDataParallel(\n",
    "        model, \n",
    "        device_ids=[cfg.local_rank], \n",
    "        )\n",
    "    \n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "\n",
    "    # ========== Training ==========\n",
    "    if cfg.local_rank == 0:\n",
    "        print(\"=\"*25)\n",
    "        print(\"Give me warp {}, Mr. Sulu.\".format(cfg.world_size))\n",
    "        print(\"=\"*25)\n",
    "    \n",
    "    best_loss= 1_000_000\n",
    "    val_loss= 1_000_000\n",
    "\n",
    "    for epoch in range(0, cfg.epochs+1):\n",
    "        if epoch != 0:\n",
    "            tstart= time.time()\n",
    "            train_dl.sampler.set_epoch(epoch)\n",
    "    \n",
    "            # Train loop\n",
    "            model.train()\n",
    "            total_loss = []\n",
    "            for i, (x, y) in enumerate(train_dl):\n",
    "                x = x.to(cfg.local_rank)\n",
    "                y = y.to(cfg.local_rank)\n",
    "        \n",
    "                with autocast(cfg.device.type):\n",
    "                    logits = model(x)\n",
    "                    \n",
    "                loss = criterion(logits, y)\n",
    "        \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "        \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "        \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                total_loss.append(loss.item())\n",
    "                \n",
    "                if ema_model is not None:\n",
    "                    ema_model.update(model)\n",
    "                    \n",
    "                if cfg.local_rank == 0 and (len(total_loss) >= cfg.logging_steps or i == 0):\n",
    "                    train_loss = np.mean(total_loss)\n",
    "                    total_loss = []\n",
    "                    print(\"Epoch {}:     Train MAE: {:.2f}     Val MAE: {:.2f}     Time: {}     Step: {}/{}\".format(\n",
    "                        epoch, \n",
    "                        train_loss,\n",
    "                        val_loss,\n",
    "                        format_time(time.time() - tstart),\n",
    "                        i+1, \n",
    "                        len(train_dl)+1, \n",
    "                    ))\n",
    "    \n",
    "        # ========== Valid ==========\n",
    "        model.eval()\n",
    "        val_logits = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_dl, disable=cfg.local_rank != 0):\n",
    "                x = x.to(cfg.local_rank)\n",
    "                y = y.to(cfg.local_rank)\n",
    "    \n",
    "                with autocast(cfg.device.type):\n",
    "                    if ema_model is not None:\n",
    "                        out = ema_model.module(x)\n",
    "                    else:\n",
    "                        out = model(x)\n",
    "\n",
    "                val_logits.append(out.cpu())\n",
    "                val_targets.append(y.cpu())\n",
    "\n",
    "            val_logits= torch.cat(val_logits, dim=0)\n",
    "            val_targets= torch.cat(val_targets, dim=0)\n",
    "                \n",
    "            loss = criterion(val_logits, val_targets).item()\n",
    "\n",
    "        # Gather loss\n",
    "        v = torch.tensor([loss], device=cfg.local_rank)\n",
    "        torch.distributed.all_reduce(v, op=dist.ReduceOp.SUM)\n",
    "        val_loss = (v[0] / cfg.world_size).item()\n",
    "    \n",
    "        # ========== Weights / Early stopping ==========\n",
    "        stop_train = torch.tensor([0], device=cfg.local_rank)\n",
    "        if cfg.local_rank == 0:\n",
    "            es= cfg.early_stopping\n",
    "            if val_loss < best_loss:\n",
    "                print(\"New best: {:.2f} -> {:.2f}\".format(best_loss, val_loss))\n",
    "                print(\"Saved weights..\")\n",
    "                best_loss = val_loss\n",
    "                if ema_model is not None:\n",
    "                    torch.save(ema_model.module.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "        \n",
    "                es[\"streak\"] = 0\n",
    "            else:\n",
    "                es= cfg.early_stopping\n",
    "                es[\"streak\"] += 1\n",
    "                if es[\"streak\"] > es[\"patience\"]:\n",
    "                    print(\"Ending training (early_stopping).\")\n",
    "                    stop_train = torch.tensor([1], device=cfg.local_rank)\n",
    "        \n",
    "        # Exits training on all ranks\n",
    "        dist.broadcast(stop_train, src=0)\n",
    "        if stop_train.item() == 1:\n",
    "            return\n",
    "\n",
    "    return\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # GPU Specs\n",
    "    rank = int(os.environ[\"RANK\"])\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    _, total = torch.cuda.mem_get_info(device=rank)\n",
    "\n",
    "    # Init\n",
    "    setup(rank, world_size)\n",
    "    time.sleep(rank)\n",
    "    print(f\"Rank: {rank}, World size: {world_size}, GPU memory: {total / 1024**3:.2f}GB\", flush=True)\n",
    "    time.sleep(world_size - rank)\n",
    "\n",
    "    # Seed\n",
    "    set_seed(cfg.seed+rank)\n",
    "\n",
    "    # Run\n",
    "    cfg.local_rank= rank\n",
    "    cfg.world_size= world_size\n",
    "    main(cfg)\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_TRAIN:\n",
    "    print(\"Starting training..\")\n",
    "    !set OMP_NUM_THREADS=1 && torchrun --nproc_per_node=1 _train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc8ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
