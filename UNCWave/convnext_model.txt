Net(
  (backbone): FeatureListNet(
    (stem_0): Sequential(
      (0): ReflectionPad2d((1, 1, 80, 80))
      (1): Conv2d(5, 96, kernel_size=(4, 4), stride=(4, 1), padding=(0, 2))
      (2): Conv2d(96, 96, kernel_size=(4, 4), stride=(4, 1), padding=(0, 1))
    )
    (stem_1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
    (stages_0): ConvNeXtStage(
      (downsample): Identity()
      (blocks): Sequential(
        (0): ConvNeXtBlock(
          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (1): ConvNeXtBlock(
          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (2): ConvNeXtBlock(
          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
      )
    )
    (stages_1): ConvNeXtStage(
      (downsample): Sequential(
        (0): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (blocks): Sequential(
        (0): ConvNeXtBlock(
          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (1): ConvNeXtBlock(
          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (2): ConvNeXtBlock(
          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
      )
    )
    (stages_2): ConvNeXtStage(
      (downsample): Sequential(
        (0): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (blocks): Sequential(
        (0): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (1): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (2): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (3): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (4): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (5): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (6): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (7): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (8): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (9): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (10): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (11): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (12): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (13): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (14): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (15): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (16): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (17): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (18): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (19): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (20): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (21): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (22): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (23): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (24): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (25): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (26): ConvNeXtBlock(
          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
      )
    )
    (stages_3): ConvNeXtStage(
      (downsample): Sequential(
        (0): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
      (blocks): Sequential(
        (0): ConvNeXtBlock(
          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): InstanceNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (1): ConvNeXtBlock(
          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): InstanceNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
        (2): ConvNeXtBlock(
          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): InstanceNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (shortcut): Identity()
          (drop_path): Identity()
        )
      )
    )
  )
  (decoder): UnetDecoder2d(
    (blocks): ModuleList(
      (0): DecoderBlock2d(
        (upsample): UpSample(
          (deconv): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))
        )
        (attention1): Attention2d(
          (attention): Identity()
        )
        (conv1): ConvBnAct2d(
          (conv): Conv2d(1152, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (norm): Identity()
          (act): ReLU(inplace=True)
        )
        (conv2): ConvBnAct2d(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (norm): Identity()
          (act): ReLU(inplace=True)
        )
        (attention2): Attention2d(
          (attention): Identity()
        )
      )
      (1): DecoderBlock2d(
        (upsample): UpSample(
          (deconv): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))
        )
        (attention1): Attention2d(
          (attention): Identity()
        )
        (conv1): ConvBnAct2d(
          (conv): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (norm): Identity()
          (act): ReLU(inplace=True)
        )
        (conv2): ConvBnAct2d(
          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (norm): Identity()
          (act): ReLU(inplace=True)
        )
        (attention2): Attention2d(
          (attention): Identity()
        )
      )
      (2): DecoderBlock2d(
        (upsample): UpSample(
          (deconv): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
        )
        (attention1): Attention2d(
          (attention): Identity()
        )
        (conv1): ConvBnAct2d(
          (conv): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (norm): Identity()
          (act): ReLU(inplace=True)
        )
        (conv2): ConvBnAct2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (norm): Identity()
          (act): ReLU(inplace=True)
        )
        (attention2): Attention2d(
          (attention): Identity()
        )
      )
    )
  )
  (seg_head): SegmentationHead2d(
    (conv): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (upsample): UpSample(
      (upsample_non_trainable): Upsample(scale_factor=(1.0, 1.0), mode='bilinear')
    )
  )
)


Epoch 0 Validation:   0%|          | 0/2 [00:00<?, ?it/s]
[Net] - Stem x shape : torch.Size([8, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([8, 96, 72, 72]), torch.Size([8, 192, 36, 36]), torch.Size([8, 384, 18, 18]), torch.Size([8, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([8, 384, 18, 18]) | s1 shape torch.Size([8, 192, 36, 36]) |s2 shape torch.Size([8, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([8, 768, 9, 9]) | skip shape torch.Size([8, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([8, 128, 18, 18]) | skip shape torch.Size([8, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([8, 64, 36, 36]) | skip shape torch.Size([8, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([8, 768, 9, 9]), torch.Size([8, 128, 18, 18]), torch.Size([8, 64, 36, 36]), torch.Size([8, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([8, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([8, 1, 70, 70])

Epoch 0 Validation:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]

[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([8, 384, 18, 18]) | s1 shape torch.Size([8, 192, 36, 36]) |s2 shape torch.Size([8, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([8, 768, 9, 9]) | skip shape torch.Size([8, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([8, 128, 18, 18]) | skip shape torch.Size([8, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([8, 64, 36, 36]) | skip shape torch.Size([8, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Segmentation Head 2d] forward--
[Net] - Stem x shape : torch.Size([2, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([2, 96, 72, 72]), torch.Size([2, 192, 36, 36]), torch.Size([2, 384, 18, 18]), torch.Size([2, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([2, 768, 9, 9]), torch.Size([2, 128, 18, 18]), torch.Size([2, 64, 36, 36]), torch.Size([2, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([2, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([2, 1, 70, 70])
Epoch 0 Validation: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Segmentation Head 2d] forward--
Epoch 1 Training:   0%|          | 0/2 [00:00<?, ?it/s][Net] - Stem x shape : torch.Size([8, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([8, 96, 72, 72]), torch.Size([8, 192, 36, 36]), torch.Size([8, 384, 18, 18]), torch.Size([8, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([8, 384, 18, 18]) | s1 shape torch.Size([8, 192, 36, 36]) |s2 shape torch.Size([8, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([8, 768, 9, 9]) | skip shape torch.Size([8, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([8, 128, 18, 18]) | skip shape torch.Size([8, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([8, 64, 36, 36]) | skip shape torch.Size([8, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([8, 768, 9, 9]), torch.Size([8, 128, 18, 18]), torch.Size([8, 64, 36, 36]), torch.Size([8, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([8, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([8, 1, 70, 70])
Epoch 1 Training:  50%|█████     | 1/2 [00:05<00:05,  5.47s/it][Net] - Stem x shape : torch.Size([2, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([2, 96, 72, 72]), torch.Size([2, 192, 36, 36]), torch.Size([2, 384, 18, 18]), torch.Size([2, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([2, 768, 9, 9]), torch.Size([2, 128, 18, 18]), torch.Size([2, 64, 36, 36]), torch.Size([2, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([2, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([2, 1, 70, 70])
Epoch 1 Training: 100%|██████████| 2/2 [00:07<00:00,  3.51s/it]
Epoch 1 Validation:   0%|          | 0/2 [00:00<?, ?it/s][Net] - Stem x shape : torch.Size([8, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([8, 96, 72, 72]), torch.Size([8, 192, 36, 36]), torch.Size([8, 384, 18, 18]), torch.Size([8, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([8, 384, 18, 18]) | s1 shape torch.Size([8, 192, 36, 36]) |s2 shape torch.Size([8, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([8, 768, 9, 9]) | skip shape torch.Size([8, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([8, 128, 18, 18]) | skip shape torch.Size([8, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([8, 64, 36, 36]) | skip shape torch.Size([8, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([8, 768, 9, 9]), torch.Size([8, 128, 18, 18]), torch.Size([8, 64, 36, 36]), torch.Size([8, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([8, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([8, 1, 70, 70])
Epoch 1 Validation:  50%|█████     | 1/2 [00:02<00:02,  2.86s/it][UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([8, 384, 18, 18]) | s1 shape torch.Size([8, 192, 36, 36]) |s2 shape torch.Size([8, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([8, 768, 9, 9]) | skip shape torch.Size([8, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([8, 128, 18, 18]) | skip shape torch.Size([8, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([8, 64, 36, 36]) | skip shape torch.Size([8, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Segmentation Head 2d] forward--
[Net] - Stem x shape : torch.Size([2, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([2, 96, 72, 72]), torch.Size([2, 192, 36, 36]), torch.Size([2, 384, 18, 18]), torch.Size([2, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([2, 768, 9, 9]), torch.Size([2, 128, 18, 18]), torch.Size([2, 64, 36, 36]), torch.Size([2, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([2, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([2, 1, 70, 70])
Epoch 1 Validation: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it][UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Segmentation Head 2d] forward--

---------------
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([8, 384, 18, 18]) | s1 shape torch.Size([8, 192, 36, 36]) |s2 shape torch.Size([8, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([8, 768, 9, 9]) | skip shape torch.Size([8, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([8, 128, 18, 18]) | skip shape torch.Size([8, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([8, 64, 36, 36]) | skip shape torch.Size([8, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Segmentation Head 2d] forward--
[Net] - Stem x shape : torch.Size([2, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([2, 96, 72, 72]), torch.Size([2, 192, 36, 36]), torch.Size([2, 384, 18, 18]), torch.Size([2, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([2, 768, 9, 9]), torch.Size([2, 128, 18, 18]), torch.Size([2, 64, 36, 36]), torch.Size([2, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([2, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([2, 1, 70, 70])


---------------

[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([8, 384, 18, 18]) | s1 shape torch.Size([8, 192, 36, 36]) |s2 shape torch.Size([8, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([8, 768, 9, 9]) | skip shape torch.Size([8, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([8, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([8, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([8, 128, 18, 18]) | skip shape torch.Size([8, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([8, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([8, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([8, 64, 36, 36]) | skip shape torch.Size([8, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([8, 32, 72, 72])
[Segmentation Head 2d] forward--
[Net] - Stem x shape : torch.Size([2, 5, 1000, 70])
[Net] - Encoder x shape : [torch.Size([2, 96, 72, 72]), torch.Size([2, 192, 36, 36]), torch.Size([2, 384, 18, 18]), torch.Size([2, 768, 9, 9])]
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Net] - Decoder x shape : [torch.Size([2, 768, 9, 9]), torch.Size([2, 128, 18, 18]), torch.Size([2, 64, 36, 36]), torch.Size([2, 32, 72, 72])]
[Segmentation Head 2d] forward--
[Net] - Decoder x_seg shape : torch.Size([2, 1, 70, 70])
[Net] - Decoder x_seg x1500 + 3000 shape : torch.Size([2, 1, 70, 70])

---------------
[UnetDecoder2d] - forward length of feats and shapes 3 | s0 shape torch.Size([2, 384, 18, 18]) | s1 shape torch.Size([2, 192, 36, 36]) |s2 shape torch.Size([2, 96, 72, 72]) |
[DecoderBlock2d] -- forward x shape torch.Size([2, 768, 9, 9]) | skip shape torch.Size([2, 384, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 1152, 18, 18])
[ConvBnAct2d] --forward | x shape torch.Size([2, 128, 18, 18])
[Attention2d] --forward | x shape torch.Size([2, 128, 18, 18])
[DecoderBlock2d] -- forward x shape torch.Size([2, 128, 18, 18]) | skip shape torch.Size([2, 192, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 320, 36, 36])
[ConvBnAct2d] --forward | x shape torch.Size([2, 64, 36, 36])
[Attention2d] --forward | x shape torch.Size([2, 64, 36, 36])
[DecoderBlock2d] -- forward x shape torch.Size([2, 64, 36, 36]) | skip shape torch.Size([2, 96, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 160, 72, 72])
[ConvBnAct2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Attention2d] --forward | x shape torch.Size([2, 32, 72, 72])
[Segmentation Head 2d] forward--